<?xml version="1.0" encoding="UTF-8" ?>
<!--
Copyright (c) 2017. Zuercher Hochschule fuer Angewandte Wissenschaften
All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may
not use this file except in compliance with the License. You may obtain
a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
License for the specific language governing permissions and limitations
under the License.

Author: Balazs Meszaros
-->
<discocomponent>
    <properties>
        <!-- these properties can be set over HTTP parameters as well; they will be inserted automatically -->
        <property name="staticoutput" value="false" />
        <property name="included" value="false" />
		<property name="outputtype" value="append" />
		<property name="openports" value="8080,18080" />
    </properties>

	<dependencies>
		<dependency name="heat" state="start">
			<variable name="slavecount" />
			<variable name="mastername" />
			<variable name="slavename" />
		</dependency>
		<dependency name="shell" state="start" />
		<dependency name="hadoop" />
	</dependencies>

	<functions>
	</functions>

	<globaloutput />

	<output />

	<sparkstart><![CDATA[
# install Apache Spark on master node
deploymentLog "downloading Apache Spark to master node"
su ubuntu -c "sudo mkdir /home/ubuntu/spark"
cd /home/ubuntu/spark
chown ubuntu:ubuntu /home/ubuntu/spark
su ubuntu -c "wget http://reposerver/spark/spark-2.1.0-bin-hadoop2.7.tgz"

su ubuntu -c "parallel-ssh -t 2000 -h /home/ubuntu/hosts.lst \"sudo sh -c \\\"echo \\\\\\\"SPARK_HOME=\\\\\\\\\\\\\\\"/usr/lib/spark/spark\\\\\\\\\\\\\\\"\\\\nJAVA_HOME=\\\\\\\\\\\\\\\"/usr/lib/java/jdk\\\\\\\\\\\\\\\"\\\\\\\" >> \\\/etc\\\/environment\\\"\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"sudo mkdir /usr/lib/spark\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"sudo chown ubuntu:ubuntu /usr/lib/spark/\""
su ubuntu -c "parallel-scp -h ~/hosts.lst ~/spark/spark-2.1.0-bin-hadoop2.7.tgz /usr/lib/spark"
su ubuntu -c "parallel-ssh -t 2000 -h /home/ubuntu/hosts.lst \"tar -xzf /usr/lib/spark/spark-2.1.0-bin-hadoop2.7.tgz\""
#su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"mv spark-2.1.0-bin-hadoop2.7 /usr/lib/spark/\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"mv spark-2.1.0-bin-hadoop2.7 /usr/lib/spark\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"ln -s /usr/lib/spark/spark-2.1.0-bin-hadoop2.7/ /usr/lib/spark/spark\""

# su ubuntu -c "/usr/lib/hadoop/hadoop/bin/hdfs dfs -mkdir /sparkoutput"

# create default config file for Spark
cat - > /home/ubuntu/spark-default.conf << 'EOF'
spark.master    yarn
spark.eventLog.enabled	true
spark.eventLog.dir /usr/lib/spark/spark/logs
spark.history.ui.port 18080
spark.yarn.historyServer.address $mastername$:18080
spark.history.provider org.apache.spark.deploy.history.FsHistoryProvider
spark.history.fs.logDirectory /usr/lib/spark/spark/logs
EOF

su ubuntu -c "parallel-scp -h ~/hosts.lst /home/ubuntu/spark-default.conf /usr/lib/spark/spark/conf/spark-defaults.conf"

# add $mastername$ to the following file for starting a worker on the master node
cat - > /usr/lib/spark/spark/conf/slaves << 'EOF'
]]></sparkstart>


	<sparkend><![CDATA[EOF

su ubuntu -c "/usr/lib/spark/spark/sbin/start-master.sh"
su ubuntu -c "/usr/lib/spark/spark/sbin/start-slaves.sh"

# start Spark History Server
su ubuntu -c "/usr/lib/spark/spark/sbin/start-history-server.sh"

echo 'export PATH=$PATH:/usr/lib/spark/spark/bin' >> /etc/bash.bashrc
echo 'export HADOOP_CONF_DIR=/etc/hadoop' >> /etc/bash.bashrc

deploymentLog "Spark installed and started"

]]></sparkend>


</discocomponent>
