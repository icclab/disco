<?xml version="1.0" encoding="UTF-8" ?>
<discocomponent>
    <properties>
        <!-- these properties can be set over HTTP parameters as well; they will be inserted automatically -->
        <property name="staticoutput" value="false" />
        <property name="included" value="false" />
		<property name="outputtype" value="append" />
    </properties>

	<dependencies>
		<dependency name="heat" state="start">
			<variable name="slavecount" />
			<variable name="mastername" />
			<variable name="slavename" />
		</dependency>
		<dependency name="shell" state="start" />
	</dependencies>

	<functions>
	</functions>

	<globaloutput />

	<output />

	<sparkstart><![CDATA[
# install Apache Spark on master node
deploymentLog "downloading Apache Spark to master node"
su ubuntu -c "sudo mkdir /home/ubuntu/spark"
cd /home/ubuntu/spark
chown ubuntu:ubuntu /home/ubuntu/spark
#su ubuntu -c "wget http://d3kbcqa49mib13.cloudfront.net/spark-2.0.0-bin-hadoop2.7.tgz"
su ubuntu -c "wget http://reposerver/spark/spark-2.0.0-bin-hadoop2.7.tgz"

#su ubuntu -c "tar -xzf /home/ubuntu/spark/spark-2.0.0-bin-hadoop2.7.tgz"
su ubuntu -c "parallel-ssh -t 2000 -h /home/ubuntu/hosts.lst \"sudo sh -c \\\"echo \\\\\\\"SPARK_HOME=\\\\\\\\\\\\\\\"/usr/lib/spark/spark\\\\\\\\\\\\\\\"\\\\nJAVA_HOME=\\\\\\\\\\\\\\\"/usr/lib/java/jdk\\\\\\\\\\\\\\\"\\\\\\\" >> \\\/etc\\\/environment\\\"\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"sudo mkdir /usr/lib/spark\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"sudo chown ubuntu:ubuntu /usr/lib/spark/\""
su ubuntu -c "parallel-scp -h ~/hosts.lst ~/spark/spark-2.0.0-bin-hadoop2.7.tgz /usr/lib/spark"
su ubuntu -c "parallel-ssh -t 2000 -h /home/ubuntu/hosts.lst \"tar -xzf /usr/lib/spark/spark-2.0.0-bin-hadoop2.7.tgz\""
#su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"mv spark-2.0.0-bin-hadoop2.7 /usr/lib/spark/\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"mv spark-2.0.0-bin-hadoop2.7 /usr/lib/spark\""
su ubuntu -c "parallel-ssh -t 2000 -h ~/hosts.lst \"ln -s /usr/lib/spark/spark-2.0.0-bin-hadoop2.7/ /usr/lib/spark/spark\""
cat - > /usr/lib/spark/spark/conf/slaves << 'EOF'
$mastername$
]]></sparkstart>


	<sparkend><![CDATA[EOF
su ubuntu -c "/usr/lib/spark/spark/sbin/start-master.sh"
su ubuntu -c "/usr/lib/spark/spark/sbin/start-slaves.sh"
deploymentLog "Spark installed and started"

]]></sparkend>


</discocomponent>
